{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# <font color='green'>Lending Club Loan Data Analysis</font>\n",
        "\n",
        "### DESCRIPTION\n",
        "\n",
        "Create a model that predicts whether or not a loan will be default using the historical data.\n",
        "\n",
        "### Problem Statement:  \n",
        "\n",
        "For companies like Lending Club correctly predicting whether or not a loan will be a default is very important. In this project, using the historical data from 2007 to 2015, you have to build a deep learning model to predict the chance of default for future loans. As you will see later this dataset is highly imbalanced and includes a lot of features that make this problem more challenging.\n",
        "\n",
        "**Domain:** Finance\n",
        "\n",
        "Analysis to be done: Perform data preprocessing and build a deep learning prediction model. \n",
        "\n",
        "**Content: **\n",
        "\n",
        "Dataset columns and definition:\n",
        "\n",
        " \n",
        "\n",
        "**credit.policy:** 1 if the customer meets the credit underwriting criteria of LendingClub.com, and 0 otherwise.\n",
        "\n",
        "**purpose:** The purpose of the loan (takes values \"credit_card\", \"debt_consolidation\", \"educational\", \"major_purchase\", \"small_business\", and \"all_other\").\n",
        "\n",
        "**int.rate:** The interest rate of the loan, as a proportion (a rate of 11% would be stored as 0.11). Borrowers judged by LendingClub.com to be more risky are assigned higher interest rates.\n",
        "\n",
        "**installment:** The monthly installments owed by the borrower if the loan is funded.\n",
        "\n",
        "**log.annual.inc:** The natural log of the self-reported annual income of the borrower.\n",
        "\n",
        "**dti:** The debt-to-income ratio of the borrower (amount of debt divided by annual income).\n",
        "\n",
        "**fico:** The FICO credit score of the borrower.\n",
        "\n",
        "**days.with.cr.line:** The number of days the borrower has had a credit line.\n",
        "\n",
        "**revol.bal:1** The borrower's revolving balance (amount unpaid at the end of the credit card billing cycle).\n",
        "\n",
        "**revol.util:** The borrower's revolving line utilization rate (the amount of the credit line used relative to total credit available).\n",
        "\n",
        "**inq.last.6mths:** The borrower's number of inquiries by creditors in the last 6 months.\n",
        "\n",
        "**delinq.2yrs:** The number of times the borrower had been 30+ days past due on a payment in the past 2 years.\n",
        "\n",
        "**pub.rec:** The borrower's number of derogatory public records (bankruptcy filings, tax liens, or judgments).\n",
        "\n",
        " \n",
        "\n",
        "**Steps to perform:**\n",
        "\n",
        "Perform exploratory data analysis and feature engineering and then apply feature engineering. Follow up with a deep learning model to predict whether or not the loan will be default using the historical data.\n",
        "\n",
        "**Tasks:**\n",
        "\n",
        "1.     Feature Transformation\n",
        "\n",
        "    * Transform categorical values into numerical values (discrete)\n",
        "\n",
        "2.     Exploratory data analysis of different factors of the dataset.\n",
        "\n",
        "3.     Additional Feature Engineering\n",
        "\n",
        "      * You will check the correlation between features and will drop those features which have a strong correlation\n",
        "\n",
        "    * This will help reduce the number of features and will leave you with the most relevant features\n",
        "\n",
        "4.     Modeling\n",
        "\n",
        "    * After applying EDA and feature engineering, you are now ready to build the predictive models\n",
        "\n",
        "    * In this part, you will create a deep learning model using Keras with Tensorflow backend\n",
        "\n"
      ],
      "metadata": {
        "id": "Zp7oEJOlQGSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all Important Librarys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.utils import resample\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "lwicC0RMQP-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data=pd.read_csv(\"loan_data.csv\")"
      ],
      "metadata": {
        "id": "twQ9JqBBhkvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(10)"
      ],
      "metadata": {
        "id": "DCQYgHhBQQPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this data set has 9578 rows and 14 columns\n",
        "data.shape"
      ],
      "metadata": {
        "id": "20POEb9OQQVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "BpFuraYzQQXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check null values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "DIJEYAjdQQZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum().any()"
      ],
      "metadata": {
        "id": "MDMT-42HQQb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "sv_YIrWrQQfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory data analysis of different factors of the dataset."
      ],
      "metadata": {
        "id": "q_GyaY21RuJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['not.fully.paid'].value_counts()"
      ],
      "metadata": {
        "id": "eGMVdQxYQQiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "0 - Full Paid\n",
        "\n",
        "1 - Not Paid\n",
        "\n",
        "imbalanced data"
      ],
      "metadata": {
        "id": "3PJvD_CBRzF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=data['not.fully.paid'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PFPGKmjZQQk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,6))\n",
        "sns.countplot(x=data['purpose'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7o46h_rqQQnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# purpose and not fully paid\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.countplot(x='purpose',hue='not.fully.paid',data=data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4xy7SMmJQQqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# bi variate analysis\n",
        "sns.jointplot(x='fico',y='int.rate',data=data, kind='hex', color='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Vgu6zKgNQQtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(x='fico',y='int.rate',data=data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2-Aggj0BQQvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(data['fico'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wFnavyWkQQyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(x='fico', hue='not.fully.paid', data=data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xb3cT0LHQQ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Feature Transformation\n",
        "#### Transform categorical values into numerical values (discrete)"
      ],
      "metadata": {
        "id": "qr6LvHCLSSG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle imbalanced dataset\n",
        "data['not.fully.paid'].value_counts()"
      ],
      "metadata": {
        "id": "sMUH2qhUQQ4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_fully_paid_0 = data[data['not.fully.paid']==0]\n",
        "not_fully_paid_1 = data[data['not.fully.paid']==1]"
      ],
      "metadata": {
        "id": "Lg9A5fueQQ7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_fully_paid_0.shape"
      ],
      "metadata": {
        "id": "R-8rV-eYQQ-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_fully_paid_1.shape"
      ],
      "metadata": {
        "id": "C3sGLy2lQRBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#resample\n",
        "data_minor_upsample=resample(not_fully_paid_1,replace=True,n_samples=8045)"
      ],
      "metadata": {
        "id": "zf71cp1tQREE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data=pd.concat([not_fully_paid_0,data_minor_upsample])"
      ],
      "metadata": {
        "id": "0thEbmr6QRHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#shuffle\n",
        "new_data=shuffle(new_data)"
      ],
      "metadata": {
        "id": "MX-LXnQgQRJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data['not.fully.paid'].value_counts()"
      ],
      "metadata": {
        "id": "RKKkbO_lQRNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.shape"
      ],
      "metadata": {
        "id": "i0Vv8nOJQRQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.dtypes"
      ],
      "metadata": {
        "id": "0k6BCYkWSqXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert purpose into num data\n",
        "le = LabelEncoder()"
      ],
      "metadata": {
        "id": "jzeJsYtUSqaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in new_data.columns:\n",
        "    if new_data[i].dtypes =='object':\n",
        "        new_data[i]=le.fit_transform(new_data[i])"
      ],
      "metadata": {
        "id": "xJlP2kKtSqet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.dtypes"
      ],
      "metadata": {
        "id": "fBZtYqxfSqhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Additional Feature Engineering\n",
        "\n",
        "#### You will check the correlation between features and will drop those features which have a strong correlation\n",
        "\n",
        "#### This will help reduce the number of features and will leave you with the most relevant features"
      ],
      "metadata": {
        "id": "psCHLp49S93i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.corr()"
      ],
      "metadata": {
        "id": "nASQLqtrSqji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(new_data.corr(),annot=True)"
      ],
      "metadata": {
        "id": "8DGfvBnTSqmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see the sorted results\n",
        "new_data.corr().abs()['not.fully.paid'].sort_values(ascending=False)"
      ],
      "metadata": {
        "id": "LKFpvWp_Sqtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_data.columns"
      ],
      "metadata": {
        "id": "-5ump_JNSqv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take columns\n",
        "X=new_data[['credit.policy','purpose', 'int.rate', 'installment','fico','revol.bal','revol.util','inq.last.6mths','pub.rec']]"
      ],
      "metadata": {
        "id": "ASm0A5eDSqyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "pEhjtGVBSq1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=new_data['not.fully.paid']"
      ],
      "metadata": {
        "id": "7GABg46NSq39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train set & test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=42)"
      ],
      "metadata": {
        "id": "6lCVfZPKSq6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "luBLywFbSq8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "wa61ed8STaiN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply scaling\n",
        "sc=StandardScaler()"
      ],
      "metadata": {
        "id": "OxOsuGlfTala"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)"
      ],
      "metadata": {
        "id": "sJ8UQOBETapt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### In this part, you will create a deep learning model using Keras with Tensorflow backend\n"
      ],
      "metadata": {
        "id": "twYhLbPTT5i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the architecture\n",
        "# 2 ANN layer\n",
        "model=Sequential()\n",
        "model.add(Dense(19,activation='relu',input_shape=[9]))\n",
        "model.add(Dropout(0.20))\n",
        "\n",
        "model.add(Dense(10,activation='relu'))\n",
        "model.add(Dropout(0.20))\n",
        "\n",
        "# output layer\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "ZJVRE_65TasV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "E4SKQgn-Tauz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7sCSYE6sTaxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop=EarlyStopping(monitor='val_loss',min_delta=0.001,mode='min',patience=10,verbose=1)"
      ],
      "metadata": {
        "id": "Ob0CZ4UATa0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,\n",
        "          epochs=50,\n",
        "          batch_size=256,\n",
        "          validation_data=(X_test,y_test),\n",
        "          callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "ZOLghGmMTa3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(X_train,y_train,\n",
        "          epochs=50,\n",
        "          batch_size=256,\n",
        "          validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "jkUoWtObTa5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "jpD37jayTa-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "metadata": {
        "id": "I_amG4lFTbBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "dbYQv4yOTbDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions=(y_pred>0.5).astype('int')"
      ],
      "metadata": {
        "id": "iSKWq2_pTbGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "23Xy33iNTbJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "id": "_tm4jEJgTbMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score(predictions,y_test)"
      ],
      "metadata": {
        "id": "w9QedIzJUpSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(predictions,y_test))"
      ],
      "metadata": {
        "id": "gU63bwpHUsa_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('loan_default1.h5')"
      ],
      "metadata": {
        "id": "8buP8ezBUu6P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model2 Architecture"
      ],
      "metadata": {
        "id": "PKKtUTVZVAGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the architecture model2\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "# batch Normalization\n",
        "# First ANN layer\n",
        "model1=Sequential()\n",
        "model1.add(Dense(128,activation='relu',input_shape=[9]))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.20))\n",
        "\n",
        "# Second ANN layer\n",
        "model1.add(Dense(64,activation='tanh'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.20))\n",
        "           \n",
        "\n",
        "# third ANN layer\n",
        "model1.add(Dense(32,activation='relu'))\n",
        "model1.add(BatchNormalization())\n",
        "model1.add(Dropout(0.20))\n",
        "\n",
        "# output layer\n",
        "model1.add(Dense(1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "HuhlLyODU5JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()"
      ],
      "metadata": {
        "id": "4sbPj6aWU6Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the model\n",
        "model1.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "iC-Jl_CDU6Lh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model1.fit(X_train,y_train,\n",
        "          epochs=100,\n",
        "          batch_size=256,\n",
        "          validation_data=(X_test,y_test))"
      ],
      "metadata": {
        "id": "kaPzJNSUU6N-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "id": "qxuNquDsU6Qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.evaluate(X_train,y_train)"
      ],
      "metadata": {
        "id": "aAv5C5hqU6Xd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyparameter tuning in Keras"
      ],
      "metadata": {
        "id": "xacAOKEXVpSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "-0iclkTVixdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model=Sequential()\n",
        "    \n",
        "    # first hidden layer\n",
        "    model.add(Dense(units=hp.Int('units',min_value=32,max_value=1024,step=16),\n",
        "                   activation=hp.Choice('activation',['relu','tanh']),input_shape=[9]))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('rate',min_value=0.1,max_value=0.5,step=0.1)))\n",
        "                      \n",
        "        \n",
        "    # Second hidden layer\n",
        "    model.add(Dense(units=hp.Int('units',min_value=32,max_value=1024,step=16),\n",
        "                   activation=hp.Choice('activation',['relu','tanh'])))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('rate',min_value=0.1,max_value=0.5,step=0.1)))\n",
        "    \n",
        "     # third hidden layer\n",
        "    model.add(Dense(units=hp.Int('units',min_value=32,max_value=1024,step=16),\n",
        "                   activation=hp.Choice('activation',['relu','tanh'])))\n",
        "    \n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('rate',min_value=0.1,max_value=0.5,step=0.1)))\n",
        "    \n",
        "    model.add(Dense(1,activation='sigmoid'))\n",
        "    \n",
        "    learning_rate=hp.Float('learning_rate',min_value=0.001,max_value=0.1,step=0.01)\n",
        "        \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=keras.optimizers.Adam(learning_rate),\n",
        "                 metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "aizIgtC0U6ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_leAIdFKAxAD"
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_model(kt.HyperParameters())"
      ],
      "metadata": {
        "id": "YXwVV-Z_Vxv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rtuner=kt.RandomSearch(hypermodel=build_model,\n",
        "                       objective='val_accuracy',\n",
        "                       max_trials=10                   \n",
        "                      )"
      ],
      "metadata": {
        "id": "CdcjEu21Vxyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rtuner.search(X_train,y_train,\n",
        "             epochs=50,validation_data=(X_test,y_test),\n",
        "             verbose=2)"
      ],
      "metadata": {
        "id": "CMwZSHZmVx3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "par=rtuner.get_best_hyperparameters()"
      ],
      "metadata": {
        "id": "U-6bjuBnVx6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "par"
      ],
      "metadata": {
        "id": "Po1KjHfxryYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models=rtuner.get_best_models()"
      ],
      "metadata": {
        "id": "y0DOKmAbryd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(models)"
      ],
      "metadata": {
        "id": "QQzQV68Gr-Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models[0].summary()"
      ],
      "metadata": {
        "id": "m6Y7Qyz_r-eX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=models[0].predict(X_test)>=0.5"
      ],
      "metadata": {
        "id": "u7hZpGQkr-ot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "n0-GYpVXsJj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "2QM4M5N5sJnS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}